{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf460
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 ArialMT;\f2\fnil\fcharset0 Menlo-Regular;
\f3\fnil\fcharset0 Menlo-Bold;\f4\froman\fcharset0 Times-Roman;\f5\fnil\fcharset0 HelveticaNeue;
}
{\colortbl;\red255\green255\blue255;\red255\green0\blue0;\red0\green0\blue255;\red0\green0\blue0;
\red0\green128\blue0;\red0\green0\blue0;\red49\green112\blue185;\red109\green109\blue109;\red51\green51\blue51;
\red0\green0\blue255;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid101\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid201\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid301\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid401\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid501\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid601\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid701\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid801\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid901\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1001\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1101\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid12}
{\list\listtemplateid13\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1201\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid13}
{\list\listtemplateid14\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1301\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid14}
{\list\listtemplateid15\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1401\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid15}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}{\listoverride\listid13\listoverridecount0\ls13}{\listoverride\listid14\listoverridecount0\ls14}{\listoverride\listid15\listoverridecount0\ls15}}
\margl1440\margr1440\vieww28800\viewh18000\viewkind1
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \
\cf2 Problem Statement: the problem which needs to be solved is clearly defined.  \cf0 \
Answer: \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf2 Student provides a high-level overview of the project in layman\'92s terms. Background information such as the problem domain, the project origin, and related data sets or input data is given.\cf0 \
\
Answer: \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf2 What approach did you take in coming up with a solution to this problem?\
A strategy for solving the problem, including discussion of the expected solution, has been made.\cf0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
\
Answer: \
\
\
\
\cf2 What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)\
\cf0 \
Answer: \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
\
\cf2 How did you train your model? Did you generate a synthetic dataset (if so, explain how)?\cf0 \
\
Answer: \
\
\
\
\cf2 Metrics used to measure performance of a model or result are clearly defined. Metrics are justified based on the characteristics of the problem.\cf0 \
\
Answer: \
\
\
\pard\pardeftab720\sl340\partightenfactor0

\f1\i\fs30 \cf3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 How does your model perform on a realistic dataset?\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf3 \
\pard\pardeftab720\sl340\partightenfactor0
\cf3 \
\pard\pardeftab720\sl340\partightenfactor0

\i0 \cf4 \strokec4 \
\pard\pardeftab720\sl340\partightenfactor0

\i \cf3 \strokec3 What changes did you have to make, if any?
\i0 \cf4 \strokec4 \
\
\
\
\
\pard\pardeftab720\sl340\partightenfactor0

\i \cf3 \strokec3 \
\pard\pardeftab720\sl340\partightenfactor0
\cf3 \
\
\pard\pardeftab720\sl340\partightenfactor0

\i0 \cf4 \strokec4 \
\pard\pardeftab720\sl340\partightenfactor0

\i \cf3 \strokec3 Document how you built the interface to your model.
\i0 \cf4 \strokec4 \
\
\pard\pardeftab720\sl340\partightenfactor0

\fs24 \cf4 The interface to the my model is basically the same as in the original example except the inference process. In the file \'93tensor flow_jni.cc\'94, I change the variable \'93output_names\'94 to \

\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 std::vector<std::string> output_names (\{
\f3\b \cf5 "output_length"
\f2\b0 \cf0 , 
\f3\b \cf5 "output_digit1"
\f2\b0 \cf0 , 
\f3\b \cf5 "output_digit2"
\f2\b0 \cf0 , 
\f3\b \cf5 "output_digit3"
\f2\b0 \cf0 , 
\f3\b \cf5 "output_digit4"
\f2\b0 \cf0 , 
\f3\b \cf5 "output_digit5"
\f2\b0 \cf0 \});\
which includes all names of the output layers of six classifies. After running the model to get the inference probabilities, I call the method \'93GetTopN\'94 to get the all the softmax probabilities exported by the classifier for house number length in descending order, and call the same method to return the digit with highest probability in each digit classifier. By multiplying the probabilities of length and corresponding digits, I can find the most possible house number.  \
\uc0\u8232 \
\pard\pardeftab720\sl340\partightenfactor0

\f1\i\fs30 \cf3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Make sure to report what extension(s) you have implemented and how they worked.\
\

\i0\fs24 \cf6 To localize where the numbers are in the image, I trained a localizer by using the bounding boxes provided by the SVHN. First, I import the trained model for the house number classification. By making use of the extracted details from convolutional network, I built new fully connected layers for the coordinates of each digit. The coordinates of bounding boxes are normalized so that I can train the regression model with the sigmoid_cross_entropy loss function.
\fs30  \cf4 \strokec4 \
\
\
\
\
\
\
\
\
\
\
\
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trmarr2680 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalt \clshdrawnil \clwWidth7593\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt133 \clpadl133 \clpadb133 \clpadr133 \gaph\cellx4320
\clvertalt \clshdrawnil \clwWidth4873\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt133 \clpadl133 \clpadb133 \clpadr133 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\sl720\partightenfactor0

\f4\b\fs64 \cf7 \strokec7 Capstone Project
\f1\b0\fs70 \cf4 \strokec4 \
\pard\intbl\itap1\pardeftab720\sl360\partightenfactor0

\f4\b\fs38 \cf4 Machine Learning Engineer Nanodegree
\f1\b0\fs30 \cell 
\pard\intbl\itap1\pardeftab720\sl320\qr\partightenfactor0

\f4\fs32 \cf4 Yongchao Tang
\f1\fs30 \
\pard\intbl\itap1\pardeftab720\sl280\qr\partightenfactor0
\cf4 \
\pard\intbl\itap1\pardeftab720\sl320\qr\partightenfactor0

\f4\fs32 \cf4 June 8th, 2016
\f1\fs30 \cell \lastrow\row
\pard\pardeftab720\sl340\partightenfactor0
\cf4 \
\
\pard\pardeftab720\sl600\sa357\qc\partightenfactor0

\f4\b\fs54 \cf4 Definition
\f1 \
\pard\pardeftab720\sl280\qc\partightenfactor0

\f4\i\b0\fs24 \cf4 (approximately 1 - 2 pages)
\f1\i0\fs30 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Project Overview
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, look to provide a high-level overview of the project in layman\'92s terms.\'a0Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls1\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Has an overview of the project been provided, such as the problem domain, project origin, and related datasets or input data?
\f1\i0 \
\ls1\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Has enough background information been given so that an uninformed reader would understand the problem domain and following problem statement?\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\i0\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 In modern society, various kinds of navigation applications are necessary for people to travel, commute and have played more and more important roles in every aspect of our life. When we look for a destination in a map, an incorrect house number may cause to detour and result in delay for some important events. While accurate house numbers in maps are of major importance for users to locate their destinations, adding street numbers to geographic location databases is a challenging task. This is because exact street numbers are hard to collect and sort. Before the advent of navigation applications such as Google Maps, it is easy for us to find a range of house numbers in a zone, but not to spot an exact location for a specific street number. As the demand of the precise navigation of street numbers grows, how to extract street numbers from street view images of Google street view project has become a demanding yet meaningful task. \
\pard\tx566\pardeftab720\sl340\partightenfactor0

\f1\fs30 \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 To be applied in location databases, the accuracy of transcribing house numbers from images should reach the human-level accuracy which is around 98% (Goodfellow et. al 2013). Considering the various sizes, colours, backgrounds and positions, we need to come up with some methods to recognize house numbers. \
\
Machine learning, especially deep learning method, can be a competitive candidate for such a task. Deep learning model does not need explicit programming of the recognition process. The deep learning does not require priori knowledge of the characters in images. The input data for training the deep learning model is the \'94Street View House Numbers" (SVHN) Dataset, which
\f1 \expnd0\expndtw0\kerning0
\'a0is a good large scale dataset collected from house numbers in Google Street View.
\fs30  
\f0\fs24 \kerning1\expnd0\expndtw0 It holds more than 30K images for the training and 10K for the test. Also it has additional 200K extra images containing one to five digits in each house number. \
\pard\tx566\pardeftab720\sl340\partightenfactor0

\f1\fs30 \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Problem Statement
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, you will want to clearly define the problem that you are trying to solve, including the strategy\'a0(outline of tasks)\'a0you will use to achieve the desired solution. You should also thoroughly discuss what the intended solution will be for this problem. Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls2\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Is the problem statement clearly defined? Will the reader understand what you are expecting to solve?
\f1\i0 \
\ls2\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Have you thoroughly discussed how you will attempt to solve the problem?
\f1\i0 \
\ls2\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Is an anticipated solution clearly defined? Will the reader understand what results you are looking for?\
\pard\tx566\pardeftab720\sl340\partightenfactor0

\f1\i0 \cf4 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 The target of the project is to d
\f1 \expnd0\expndtw0\kerning0
esign and implement a deep learning model that
\f0 \kerning1\expnd0\expndtw0  can recognize and transcribe the sequence of digits in an image for house numbers. My expected solution to the problem is to use the combination of deep neural net (DNN) and the convolutional neural network (CNN). \
\
A deep neural network (DNN) is composed of multiple hidden layer of units between the input and output layers. Each hidden layer consists of weights and biases, X*W+B = Y, where X is the input matrix coming from previous layer, Y is the output matrix which will be input to the next layer. To accommodate the non-linear classification, each layer also has an non-linear operation to transform the resulting matrix. The network is trained to minimize a loss function which defines the error of the training results compared with the expected targets.\
\
The convolutional neural networks (CNN) are inspired biologically from visual system of animals. The visual cells are sensitive to small sub-regions of the visual field. This sub-region is called a receptive field. The receptive fields are tiled to cover the entire visual field, and act as local filters over the input space. We can use a small matrix to represent the local field and do the matrix multiplication between this filter and a patch in an image. The results are the information we extract by the convolution operations. By moving the local field across the whole image, we actually transform the image into higher-dimension matrix from the original three-dimension (RGB format of images). The CNN can be applied to extract detailed information in an image which should be important for the recognition of sequence of digits. \
\
The whole strategy is to train six classifiers which share the input information but hold independent output layers. The sharing details of images are extracted by CNN and input to the six classifiers. One classifier is to recognize the length of digits in an image, while the rest five classifiers are for the digits recognition. The train loss function is the sum of the log probability of each digit and the length of chains, argmax( log( P(s|m) ) ).  The prediction of the model can be obtained by calculating the sequence of digits with the largest sum of the log probabilities.\
\

\f1\fs30 \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Metrics
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, you will need to clearly define the metrics or calculations you will use to measure performance of a model or result in your project. These calculations and metrics should be justified based on the characteristics of the problem and problem domain. Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls3\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Are the metrics you\'92ve chosen to measure the performance of your models clearly discussed and defined?
\f1\i0 \
\ls3\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Have you provided reasonable justification for the metrics chosen based on the problem and solution?\
\pard\tx566\pardeftab720\sl340\partightenfactor0

\f1\i0 \cf4 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 The metric of the model is explicit and chosen as the accuracy of the predictions of the whole digits chains in the images of test dataset. No partial credit is given to the results because house numbers are helpful to users only when all digits of a house number are transcribed correctly. 
\f1\fs30 \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 \
\pard\pardeftab720\sl600\sa357\qc\partightenfactor0

\f4\b\fs54 \cf4 Analysis
\f1 \
\pard\pardeftab720\sl280\qc\partightenfactor0

\f4\i\b0\fs24 \cf4 (approximately 2 - 4 pages)
\f1\i0\fs30 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Data Exploration
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, you will be expected to analyze the data you are using for the problem. This data can either be in the form of a dataset (or datasets), input data (or input files), or even an environment. The type of data should be thoroughly described and, if possible, have basic statistics and information presented (such as discussion of input features or defining characteristics about the input or environment). Any abnormalities or interesting qualities about the data that may need to be addressed have been identified (such as features that need to be transformed or the possibility of outliers). Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls4\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 If a dataset is present for this problem, have you thoroughly discussed certain features about the dataset? Has a data sample been provided to the reader?
\f1\i0 \
\ls4\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 If a dataset is present for this problem, are statistics about the dataset calculated and reported? Have any relevant results from this calculation been discussed?
\f1\i0 \
\ls4\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 If a dataset is 
\b not 
\b0 present for this problem, has discussion been made about the input space or input data for your problem?
\f1\i0 \
\ls4\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Are there any abnormalities or characteristics about the input space or dataset that need to be addressed? (categorical variables, missing values, outliers, etc.)\
\pard\tx566\pardeftab720\sl340\partightenfactor0

\f1\i0 \cf4 \
The SVHN dataset contains more than 30K images of house numbers for the training and more than 10K for the test. The numbers in each image range from one to five. Each image has different size, so we have to crop and resize the image to a uniform size. Some original images are randomly shown below:\
\
\pard\pardeftab720\partightenfactor0

\f5\fs28 \cf0 \outl0\strokewidth0 {{\NeXTGraphic unknown.png \width7280 \height3220 \noorient
}¬}\

\f1\fs30 \cf4 \outl0\strokewidth0 \strokec4 \
\pard\pardeftab720\partightenfactor0

\f5\fs28 \cf0 \outl0\strokewidth0 {{\NeXTGraphic 1__#$!@%!#__unknown.png \width7280 \height3260 \noorient
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \
\
As it is shown, the images with same house numbers can have totally different sizes and colours. The white boxes for each character is provided by the dataset, which can be used to train a object localizer. 
\f1\fs30 \cf4 \outl0\strokewidth0 \strokec4 \
\pard\tx566\pardeftab720\sl340\partightenfactor0
\cf4 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Exploratory Visualization
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, you will need to provide some form of visualization that summarizes or extracts a relevant characteristic or feature about the data. The visualization should adequately support the data being used. Discuss why this visualization was chosen and how it is relevant. Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls5\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Have you visualized a relevant characteristic or feature about the dataset or input data?
\f1\i0 \
\ls5\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Is the visualization thoroughly analyzed and discussed?
\f1\i0 \
\ls5\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 If a plot is provided, are the axes, title, and datum clearly defined?
\f1\i0 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Algorithms and Techniques
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, you will need to discuss the algorithms and techniques you intend to use for solving the problem. You should justify the use of each one based on the characteristics of the problem and the problem domain. Questions to ask yourself when writing this section:
\f1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls6\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Are the algorithms you will use, including any default variables/parameters in the project clearly defined?
\f1\i0 \
\ls6\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Are the techniques to be used thoroughly discussed and justified?
\f1\i0 \
\ls6\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Is it made clear how the input data or datasets will be handled by the algorithms and techniques chosen?\
\pard\tx566\pardeftab720\sl340\partightenfactor0

\f1\i0 \cf4 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 My final architecture is composed of four convolution layers and six softmax classifiers. Four convolution layers are used to capture the details in an image and output to the six classifiers. They contain [64, 128, 160, 192] units, respectively. Each convolution layer has max pool operation and local response normalization. The window size for the max pool is 3*3*1, and the stride is 2*2*1. Dropouts are also applied to each convolution layer. All the non-linear operations of convolution layers are rectified linear units.\
\
Every softmax classifier consists of two fully connected layers and one softmax layer. The two fully connected layers have [384, 192] units, respectively. The last sofmax layer has 7 or 11 output units. No dropout is applied to the classifier layers.\
\
I directly train the model by using SVHN by using mini-batch stochastic gradient descent. I choose the batch size of 64 by considering the memory size of my computer system. 
\f1\fs30 \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 \
\pard\tx566\pardeftab720\sl340\partightenfactor0
\cf4 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls7\ilvl0
\f4\i \cf4 \
\pard\tx566\pardeftab720\sl340\partightenfactor0

\f1\i0 \cf4 \
\pard\pardeftab720\sl600\sa357\qc\partightenfactor0

\f4\b\fs54 \cf4 Methodology
\f1 \
\pard\pardeftab720\sl280\qc\partightenfactor0

\f4\i\b0\fs24 \cf4 (approximately 3 - 5 pages)
\f1\i0\fs30 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Data Preprocessing
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, all of your preprocessing steps will need to be clearly documented, if any were necessary. From the previous section, any of the abnormalities or characteristics that you identified about the dataset will be addressed and corrected here. Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls8\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 If the algorithms chosen require preprocessing steps like feature selection or feature transformations, have they been properly documented?
\f1\i0 \
\ls8\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Based on the 
\b Data Exploration 
\b0 section, if there were abnormalities or characteristics that needed to be addressed, have they been properly corrected?
\f1\i0 \
\ls8\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 If no preprocessing is needed, has it been made clear why?\
\pard\tx566\pardeftab720\sl340\partightenfactor0

\f1\i0 \cf4 \
\pard\pardeftab720\sl340\partightenfactor0

\fs24 \cf0 \outl0\strokewidth0 An important step before applying the model on the realistic dataset is to preprocess the images of SVHN. Since the images in the dataset is not in uniform size, I first find the small rectangular bounding box that will contain individual character bounding boxes. I then expand this bounding box by 30% in both the x and the y direction, crop the image to that bounding box and resize the crop to 64 by 64 pixels. This process will induce considerable variability into processed digits sizes since images with same dimension will contain numbers of digits from one to five. Before being input into the the model, I also do the random flips, add random brightness and contrasts to the distorted images in order to increase the size of training dataset. Finally, I subtract each value in RGB by 128 and then get it divided by 128. This normalization is straightforward in the live camera android app.\
\pard\tx566\pardeftab720\sl340\partightenfactor0

\fs30 \cf4 \outl0\strokewidth0 \strokec4 \
\pard\pardeftab720\partightenfactor0

\f5\fs28 \cf0 \outl0\strokewidth0 {{\NeXTGraphic 2__#$!@%!#__unknown.png \width5060 \height5080 \noorient
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 {{\NeXTGraphic 3__#$!@%!#__unknown.png \width5060 \height5080 \noorient
}¬}\pard\pardeftab720\partightenfactor0

\f1\fs30 \cf4 \outl0\strokewidth0 \strokec4 \
\pard\tx566\pardeftab720\sl340\partightenfactor0
\cf4 \
\
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Implementation
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, the process for which metrics, algorithms, and techniques that you implemented for the given data will need to be clearly documented. It should be abundantly clear how the implementation was carried out, and discussion should be made regarding any complications that occurred during this process. Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls9\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Is it made clear how the algorithms and techniques were implemented with the given datasets or input data?
\f1\i0 \
\ls9\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Were there any complications with the original metrics or techniques that required changing prior to acquiring a solution?
\f1\i0 \
\ls9\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Was there any part of the coding process (e.g., writing complicated functions) that should be documented?
\f1\i0 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Refinement
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, you will need to discuss the process of improvement you made upon the algorithms and techniques you used in your implementation. For example, adjusting parameters for certain models to acquire improved solutions would fall under the refinement category. Your initial and final solutions should be reported, as well as any significant intermediate results as necessary. Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls10\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Has an initial solution been found and clearly reported?
\f1\i0 \
\ls10\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Is the process of improvement clearly documented, such as what techniques were used?
\f1\i0 \
\ls10\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Are intermediate and final solutions clearly reported as the process is improved?
\f1\i0 \
\pard\pardeftab720\sl600\sa357\qc\partightenfactor0

\f4\b\fs54 \cf4 Results
\f1 \
\pard\pardeftab720\sl280\qc\partightenfactor0

\f4\i\b0\fs24 \cf4 (approximately 2 - 3 pages)
\f1\i0\fs30 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Model Evaluation and Validation
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, the final model and any supporting qualities should be evaluated in detail. It should be clear how the final model was derived and why this model was chosen. In addition, some type of analysis should be used to validate the robustness of this model and its solution, such as manipulating the input data or environment to see how the model\'92s solution is affected (this is called 
\i sensitivity analysis
\i0 ). Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls11\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Is the final model reasonable and aligning with solution expectations? Are the final parameters of the model appropriate?
\f1\i0 \
\ls11\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Has the final model been tested with various inputs to evaluate whether the model generalizes well to unseen data?
\f1\i0 \
\ls11\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Is the model robust enough for the problem? Do small perturbations (changes) in training data or the input space greatly affect the results?
\f1\i0 \
\ls11\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Can results found from the model be trusted?\
\pard\tx566\pardeftab720\sl340\partightenfactor0

\f1\i0 \cf4 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 I refer to the model mentioned in the paper by Goodfellow et. al, and truncate their eight layers of convolution layers to only four layers. My model reaches the accuracy 84.1% on the test dataset of SVHN. I do not use the extra images to train my model because I cannot preprocess such a large number on my computer. \

\f1\fs30 \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 \
\
\pard\pardeftab720\sl340\partightenfactor0
\cf4 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls12\ilvl0\cf4 \
\pard\pardeftab720\sl600\sa357\qc\partightenfactor0

\f4\b\fs54 \cf4 Conclusion
\f1 \
\pard\pardeftab720\sl280\qc\partightenfactor0

\f4\i\b0\fs24 \cf4 (approximately 1 - 2 pages)
\f1\i0\fs30 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Free-Form Visualization
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, you will need to provide some form of visualization that emphasizes an important quality about the project. It is much more free-form, but should reasonably support a significant result or characteristic about the problem that you want to discuss. Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls13\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Have you visualized a relevant or important quality about the problem, dataset, input data, or results?
\f1\i0 \
\ls13\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Is the visualization thoroughly analyzed and discussed?
\f1\i0 \
\ls13\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 If a plot is provided, are the axes, title, and datum clearly defined?
\f1\i0 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Reflection
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, you will summarize the entire end-to-end problem solution and discuss one or two particular aspects of the project you found interesting or difficult. You are expected to reflect on the project as a whole to show that you have a firm understanding of the entire process employed in your work. Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls14\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Have you thoroughly summarized the entire process you used for this project?
\f1\i0 \
\ls14\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Were there any interesting aspects of the project?
\f1\i0 \
\ls14\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Were there any difficult aspects of the project?
\f1\i0 \
\ls14\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Does the final model and solution fit your expectations for the problem, and should it be used in a general setting to solve these types of problems?
\f1\i0 \
\pard\pardeftab720\sl360\sa373\partightenfactor0

\f4\b\fs32 \cf9 \strokec9 Improvement
\f1\fs38 \
\pard\pardeftab720\sl340\partightenfactor0

\f4\b0\fs30 \cf4 \strokec4 In this section, you will need to provide discussion as to how one aspect of the implementation you designed could be improved. As an example, consider ways your implementation can be made more general, and what would need to be modified. You do not need to make this improvement, but the potential solutions resulting from these changes are considered and compared/contrasted to your current solution. Questions to ask yourself when writing this section:
\f1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\partightenfactor0
\ls15\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Are there further improvements that could be made on the algorithms or techniques you used in this project?
\f1\i0 \
\ls15\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Were there algorithms or techniques you researched that you did not know how to implement, but would consider using if you knew how?
\f1\i0 \
\ls15\ilvl0
\f4\i \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 If you used your final solution as the new benchmark, do you think an even better solution exists?
\f1\i0 \
\pard\pardeftab720\sl340\partightenfactor0
\cf4 \
\pard\pardeftab720\sl340\partightenfactor0

\i \cf10 \outl0\strokewidth0 Is your model able to perform equally well on captured pictures or a live camera stream?\
\
\pard\pardeftab720\sl340\partightenfactor0

\i0\fs24 \cf0 My model has been exported to a file with the tensorflow protobuf extension. By importing it into the tensorflow android app example, I can use the model for a live camera stream. The resulting performance of the camera app is not as good as that on SVHN dataset. I guess the down side of the live camera stream is the size of characters. It is not stead for my cellphone camera to capture a steady  image with similar digits size as in training dataset. }